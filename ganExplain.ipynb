{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегодня я объясню что такое генерация изображений и как ее сделать\n",
    "\n",
    "Наверное все видели фотографии лиц, сгенерированных нейронными сетями. \n",
    "![](https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/samples_vae_crop.png)\n",
    "\n",
    "Обычно, после достаточного числа эпох эти лица почти неотличимы от настоящих! (нет)\n",
    "![](https://raw.githubusercontent.com/torch/torch.github.io/master/blog/_posts/images/samples_during_training.png)\n",
    "\n",
    "На этом занятии мы будем генерировать MNIST с помощью GAN (Generative Adversarial Network)\n",
    "\n",
    "Для начала я расскажу про необходимые понятия, которые нам пригодятся\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "Почти всегда, когда мы обучаем любую нейронку/алгоритм, мы хотим нормализовать данные. Это значит что мы переведем все данные в промежуток от 0 до 1. Кроме этого, еще неплохо было бы стандартизировать данные, привести их к одинаковому распределению. Это делается обычно так, считается среднее значение по всему датасету и стандартное отклонение от среднего. После этого из каждого элемента датасета вычитается среднее и делится на отклонение\n",
    "![](http://www-personal.umich.edu/~agrogan/NLSY/moreinfo/standardize.gif)\n",
    "Но если это всегда хорошо для данных которые мы подаем в нейронку, может быть это и хорошо для данных между слоями сети? Оказывается что да. Слой BatchNorm - нормализирует данные между слоями точно также как и обычная стандартизация. Внутри него есть два параметра - среднее и стандратное отклонение. Каждый раз когда через слой проходят данные, модель обновляет эти параметры. Ну и есть еще два параметра, как на картинке. Они обучаемые, то есть меняются в процессе backward pass. \n",
    "![](https://github.com/MaximArtemev/MSP/blob/master/%D0%A1%D0%BD%D0%B8%D0%BC%D0%BE%D0%BA%20%D1%8D%D0%BA%D1%80%D0%B0%D0%BD%D0%B0%202018-05-12%20%D0%B2%2015.30.00.png)\n",
    "\n",
    "### Deconvolution Layer\n",
    "\n",
    "![](https://i.stack.imgur.com/YyCu2.gif)\n",
    "\n",
    "Кстати, вот тут можно найти кучу приятных гифок со свертками https://github.com/vdumoulin/conv_arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
