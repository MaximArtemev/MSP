{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как правило, модели машинного обучения действуют в предположении, что матрица \"объект-признак\" является вещественнозначной, поэтому при работе с текстами сперва для каждого из них необходимо составить его признаковое описание. Для этого широко используются техники векторизации, tf-idf и пр. Рассмотрим их на примере датасета отзывов о банках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import bz2\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201030it [03:21, 996.76it/s] \n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "with bz2.BZ2File('./data/banki_responses.json.bz2', 'r') as thefile:\n",
    "    for row in tqdm(thefile):\n",
    "        resp = json.loads(row)\n",
    "        if not resp['rating_not_checked']:\n",
    "            responses.append(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Банк отказывается возвращать депозит после окончания срока действия договора. Предлагает обращаться в ЦО, где в порядке живой очереди можно забирать не более 500$/день в порядке живой очереди. Налицо отвратительное отношение к вкладчикам. Советую всем обращаться с жалобой в ЦБ и роспотребнадзор.\n"
     ]
    }
   ],
   "source": [
    "interesting_responses = [i for i in responses if 'отвратительно' in i['text']]\n",
    "print(interesting_responses[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'банк отказывается возвращать депозит после окончания срока действия договора предлагает обращаться в цо где в порядке живой очереди можно забирать не более 500 день в порядке живой очереди налицо отвратительное отношение к вкладчикам советую всем обращаться с жалобой в цб и роспотребнадзор'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r'\\b\\w+\\b'\n",
    "' '.join(re.findall(regex, interesting_responses[0]['text'].lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем выборку отзывов, предобработав их аналогичным образом, и вектор ответов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responses = [i for i in responses if i['rating_grade'] is not None]\n",
    "texts = [' '.join(re.findall(regex, i['text'].lower())) for i in responses]\n",
    "ratings = [i['rating_grade'] for i in responses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111eb99b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ratings)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый очевидный способ формирования признакового описания текстов — векторизация.\n",
    "\n",
    "Пусть у нас имеется коллекция текстов $D = \\{d_i\\}_{i=1}^l$ и словарь всех слов, встречающихся в выборке $V = \\{v_j\\}_{j=1}^d.$ В этом случае некоторый текст $d_i$ описывается вектором $(x_{ij})_{j=1}^d,$ где $$x_{ij} = \\sum_{v \\in d_i} [v = v_j].$$\n",
    "\n",
    "Таким образом, текст $d_i$ описывается вектором количества вхождений каждого слова из словаря в данный текст.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(encoding='utf8', min_df=5)\n",
    "_ = vectorizer.fit(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x76358 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 173 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(texts[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  626   817  1035  1098  1854  2532  2552  5191  5718  5720  5724  5796\n",
      "  6549  6681  6854  7064  7139  7708  7739  7740  7741  9201  9216  9231\n",
      "  9977  9996 10386 10529 10859 10901 11576 12355 12400 12401 12773 12873\n",
      " 14535 14564 14571 14591 15124 15820 15961 16287 17444 17498 17499 18032\n",
      " 18818 19932 19960 20104 20984 21630 22074 22461 23575 24462 24814 24815\n",
      " 24845 25135 25398 25922 26017 26252 27039 27117 27336 28399 30000 30023\n",
      " 30638 30715 30764 30765 30766 30767 30812 31544 31894 32528 33739 34340\n",
      " 36612 38228 39068 41174 41233 41480 41557 41723 41814 41868 43215 44172\n",
      " 45160 45638 46001 46155 46554 46590 48006 48432 48754 49174 49216 49451\n",
      " 49564 49754 49994 50182 51201 51740 51790 52515 53306 53977 54853 55779\n",
      " 56142 56271 56530 57141 57143 57876 58650 60680 61348 61599 61633 62136\n",
      " 62306 62509 63426 63454 63457 63476 63588 63930 64539 64541 64849 64880\n",
      " 64887 65678 65808 65812 65872 66139 66557 67001 67569 67571 67808 67878\n",
      " 68262 68363 68455 68490 68496 70192 70539 72515 73707 73727 73740 74201\n",
      " 74397 74695 74772 75219 75936]\n",
      "[1 1 1 1 1 1 1 1 1 2 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 1 1 3 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 7 1 1 8 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 7 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.transform(texts[:1]).indices)\n",
    "print(vectorizer.transform(texts[:1]).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF\n",
    "\n",
    "Ещё один способ работы с текстовыми данными — TF-IDF (Term Frequency–Inverse Document Frequency). Рассмотрим коллекцию текстов $D$. Для каждого уникального слова $t$ из документа $d \\in D$ вычислим следующие величины:\n",
    "\n",
    "Term Frequency – количество вхождений слова в отношении к общему числу слов в тексте: $$\\text{tf}(t, d) = \\frac{n_{td}}{\\sum_{t \\in d} n_{td}},$$ где $n_{td}$ — количество вхождений слова $t$ в текст $d$.\n",
    "Inverse Document Frequency $$\\text{idf}(t, D) = \\log \\frac{\\left| D \\right|}{\\left| \\{d\\in D: t \\in d\\} \\right|},$$ где $\\left| \\{d\\in D: t \\in d\\} \\right|$ – количество текстов в коллекции, содержащих слово $t$.\n",
    "\n",
    "Тогда для каждой пары (слово, текст) $(t, d)$ вычислим величину: $$\\text{tf-idf}(t,d, D) = \\text{tf}(t, d)\\cdot \\text{idf}(t, D).$$\n",
    "\n",
    "Отметим, что значение $\\text{tf}(t, d)$ корректируется для часто встречающихся общеупотребимых слов при помощи значения $\\text{idf}(t, D).$\n",
    "\n",
    "Признаковым описанием одного объекта $d \\in D$ будет вектор $\\bigg(\\text{tf-idf}(t,d, D)\\bigg)_{t\\in V}$, где $V$ – словарь всех слов, встречающихся в коллекции $D$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(encoding='utf8', min_df=5)\n",
    "_ = vectorizer.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x76358 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 173 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(texts[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75936 75219 74772 74695 74397 74201 73740 73727 73707 72515 70539 70192\n",
      " 68496 68490 68455 68363 68262 67878 67808 67571 67569 67001 66557 66139\n",
      " 65872 65812 65808 65678 64887 64880 64849 64541 64539 63930 63588 63476\n",
      " 63457 63454 63426 62509 62306 62136 61633 61599 61348 60680 58650 57876\n",
      " 57143 57141 56530 56271 56142 55779 54853 53977 53306 52515 51790 51740\n",
      " 51201 50182 49994 49754 49564 49451 49216 49174 48754 48432 48006 46590\n",
      " 46554 46155 46001 45638 45160 44172 43215 41868 41814 41723 41557 41480\n",
      " 41233 41174 39068 38228 36612 34340 33739 32528 31894 31544 30812 30767\n",
      " 30766 30765 30764 30715 30638 30023 30000 28399 27336 27117 27039 26252\n",
      " 26017 25922 25398 25135 24845 24815 24814 24462 23575 22461 22074 21630\n",
      " 20984 20104 19960 19932 18818 18032 17499 17498 17444 16287 15961 15820\n",
      " 15124 14591 14571 14564 14535 12873 12773 12401 12400 12355 11576 10901\n",
      " 10859 10529 10386  9996  9977  9231  9216  9201  7741  7740  7739  7708\n",
      "  7139  7064  6854  6681  6549  5796  5724  5720  5718  5191  2552  2532\n",
      "  1854  1098  1035   817   626]\n",
      "[ 0.05018819  0.12368713  0.10360912  0.07999564  0.02424115  0.05048472\n",
      "  0.03505076  0.05008284  0.08663099  0.09230501  0.05068532  0.12253009\n",
      "  0.03760316  0.04359161  0.04126231  0.07970485  0.07317581  0.19427578\n",
      "  0.08545534  0.0770788   0.04304144  0.07161861  0.11331295  0.08587092\n",
      "  0.04803165  0.08323131  0.06060702  0.03941657  0.03733075  0.03857549\n",
      "  0.12146572  0.04863372  0.05264438  0.10252958  0.02955603  0.0950179\n",
      "  0.09927005  0.11540902  0.10887833  0.04560757  0.03413512  0.12096387\n",
      "  0.03183466  0.0470889   0.06854578  0.04789541  0.12096387  0.08343477\n",
      "  0.10265328  0.07933393  0.09207866  0.06946595  0.08956097  0.03234305\n",
      "  0.0765138   0.0627802   0.07891041  0.09180104  0.08008641  0.07933393\n",
      "  0.05668065  0.06418399  0.06543211  0.09312901  0.05092452  0.13519176\n",
      "  0.11751301  0.05588994  0.12096387  0.08071585  0.08531965  0.06228753\n",
      "  0.04536286  0.08326019  0.03250904  0.08107887  0.09673368  0.04742244\n",
      "  0.02857251  0.08137658  0.06706374  0.10887833  0.06629939  0.09368703\n",
      "  0.06160098  0.0666123   0.04735817  0.04102885  0.03853438  0.12048027\n",
      "  0.11159721  0.09697473  0.08804444  0.09875681  0.03838217  0.04196518\n",
      "  0.03475003  0.07588492  0.05745062  0.0391519   0.06453991  0.02101761\n",
      "  0.05347043  0.10146521  0.04666356  0.08594147  0.03769961  0.04181323\n",
      "  0.06027444  0.07777249  0.04269048  0.07644436  0.10342065  0.05811036\n",
      "  0.08343394  0.05828596  0.05017377  0.02401224  0.07293427  0.04248957\n",
      "  0.07344943  0.07377121  0.04949278  0.06979788  0.09544459  0.03097944\n",
      "  0.07730256  0.0778685   0.04446729  0.05932385  0.02439678  0.09976079\n",
      "  0.06468213  0.03262235  0.09163721  0.10228558  0.0787036   0.07939864\n",
      "  0.10928132  0.09356099  0.07467955  0.06385749  0.08043241  0.0208522\n",
      "  0.08414522  0.10437576  0.03205227  0.07692027  0.09039451  0.11658005\n",
      "  0.06057549  0.04543664  0.03346923  0.02986002  0.02818003  0.05883337\n",
      "  0.07788779  0.0702281   0.11771808  0.08047924  0.11303876  0.03810512\n",
      "  0.05036483  0.03605272  0.01961234  0.07056537  0.09936676  0.10510258\n",
      "  0.12969742  0.0471806   0.05123554  0.04517028  0.04522644]\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.transform(texts[:1]).indices)\n",
    "print(vectorizer.transform(texts[:1]).data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация и стемминг\n",
    "\n",
    "Заметим, что одно и то же слово может встречаться в различных формах (например, \"сотрудник\" и \"сотрудника\"), но описанные выше методы интерпретируют их как различные слова, что делает признаковое описание избыточным. Устранить эту проблему можно при помощи лемматизации и стемминга.\n",
    "\n",
    "###### Стемминг\n",
    "\n",
    "Stemming – это процесс нахождения основы слова. В результате применения данной процедуры однокоренные слова, как правило, преобразуются к одинаковому виду.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры стемминга:\n",
    "\n",
    "Word  | Stem\n",
    "------------- | -------------\n",
    "вагон  | вагон\n",
    "вагона |\tвагон\n",
    "вагоне |\tвагон\n",
    "вагонов |\tвагон\n",
    "вагоном |\tвагон\n",
    "вагоны |\tвагон\n",
    "важная |\tважн\n",
    "важнее |\tважн\n",
    "важнейшие |\tважн\n",
    "важнейшими | важн\n",
    "важничал |\tважнича\n",
    "важно |\tважн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "машин обучен\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.snowball.RussianStemmer()\n",
    "print(stemmer.stem('машинное'), stemmer.stem('обучение'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:23<00:00, 42.49it/s]\n"
     ]
    }
   ],
   "source": [
    "def stem_text(text, stemmer):\n",
    "    tokens = text.split()\n",
    "    return ' '.join(map(lambda w: stemmer.stem(w), tokens))\n",
    "\n",
    "stemmed_texts = []\n",
    "for t in tqdm(texts[:1000]):\n",
    "    stemmed_texts.append(stem_text(t, stemmer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "отвратительное отношение к вкладчикам пришел пополнить свой вклад отказали сидят довольные и сытые сотрудники и ничего объяснять не собираются говорят мол к июлю все будет известно а что будет очередной банк который так легко готов потерять лицо и репутацию как заявляют клерки всего то\n"
     ]
    }
   ],
   "source": [
    "print(texts[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "отвратительн отношен к вкладчик пришел пополн сво вклад отказа сид довольн и сыт сотрудник и нич объясня не собира говор мол к июл все будет известн а что будет очередн банк котор так легк гот потеря лиц и репутац как заявля клерк всег то\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_texts[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация\n",
    "\n",
    "Лемматизация — процесс приведения слова к его нормальной форме (лемме):\n",
    "\n",
    "для существительных — именительный падеж, единственное число;\n",
    "для прилагательных — именительный падеж, единственное число, мужской род;\n",
    "для глаголов, причастий, деепричастий — глагол в инфинитиве.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация\n",
    "\n",
    "Воспользуемся изученными методами обработки текстов для решения задачи классификации отзывов на отзывы с положительной оценкой и отзывы с отрицательной оценкой. Будем считать отзывы с оценками 4-5 положительными, а остальные — отрицательными.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(encoding='utf8', min_df=5)\n",
    "_ = vectorizer.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = vectorizer.transform(texts)\n",
    "Y = (np.array(ratings) > 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/max/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:55<00:00, 55.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.963, ACC: 0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(X.shape[0], n_iter=1, test_size=0.3)\n",
    "for train_ids, test_ids in cv:\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X[train_ids], Y[train_ids])\n",
    "    preds = lr.predict_proba(X[test_ids])[:,1]\n",
    "    print('ROC-AUC: %.3f, ACC: %.3f' % (roc_auc_score(Y[test_ids], preds), \n",
    "                                        accuracy_score(Y[test_ids], (preds > 0.5).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(encoding='utf8', min_df=5)\n",
    "_ = vectorizer.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.transform(texts)\n",
    "Y = (np.array(ratings) > 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.974, ACC: 0.944\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(X.shape[0], n_iter=1, test_size=0.3)\n",
    "for train_ids, test_ids in cv:\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X[train_ids], Y[train_ids])\n",
    "    preds = lr.predict_proba(X[test_ids])[:,1]\n",
    "    print('ROC-AUC: %.3f, ACC: %.3f' % (roc_auc_score(Y[test_ids], preds), \n",
    "                                        accuracy_score(Y[test_ids], (preds > 0.5).astype(int))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "спасибо, 13.67\n",
      "приятно, 10.54\n",
      "благодарность, 9.53\n",
      "быстро, 8.33\n",
      "доволен, 6.88\n",
      "поблагодарить, 6.39\n",
      "оперативно, 6.14\n",
      "очень, 5.95\n",
      "всегда, 5.58\n",
      "очередей, 5.17\n",
      "оперативность, 5.08\n",
      "молодцы, 4.95\n",
      "выразить, 4.72\n",
      "вопросы, 4.71\n",
      "отметить, 4.70\n",
      "понравилось, 4.58\n",
      "проблем, 4.49\n",
      "нравится, 4.47\n",
      "все, 4.44\n",
      "ткс, 4.32\n",
      "хочу, 4.20\n",
      "большое, 4.17\n",
      "положительный, 3.97\n",
      "удобно, 3.90\n",
      "порадовало, 3.88\n",
      "довольна, 3.80\n",
      "сразу, 3.79\n",
      "оценку, 3.75\n",
      "огромное, 3.73\n",
      "...\n",
      "могут, -2.56\n",
      "звонки, -2.57\n",
      "часа, -2.60\n",
      "2014, -2.61\n",
      "сих, -2.61\n",
      "должна, -2.63\n",
      "говорят, -2.67\n",
      "якобы, -2.69\n",
      "пор, -2.71\n",
      "вопрос, -2.73\n",
      "опять, -2.74\n",
      "сегодня, -2.76\n",
      "клиентов, -2.82\n",
      "видимо, -2.84\n",
      "что, -2.87\n",
      "нельзя, -2.89\n",
      "ладно, -2.93\n",
      "ничего, -3.04\n",
      "должен, -3.05\n",
      "звоню, -3.11\n",
      "сказали, -3.13\n",
      "нет, -3.33\n",
      "невозможно, -3.47\n",
      "никто, -3.63\n",
      "ответа, -3.68\n",
      "вы, -3.71\n",
      "почему, -3.92\n",
      "зачем, -4.07\n",
      "ответ, -4.35\n"
     ]
    }
   ],
   "source": [
    "f_weights = zip(vectorizer.get_feature_names(), lr.coef_[0])\n",
    "f_weights = sorted(f_weights, key=lambda i: i[1])\n",
    "for i in range(1,30):\n",
    "    print('%s, %.2f' % f_weights[-i])\n",
    "    \n",
    "print('...')\n",
    "for i in reversed(range(1,30)):\n",
    "    print('%s, %.2f' % f_weights[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
